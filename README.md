ğŸ‘‹ Hi, my name is Rodrigo and Iâ€™m a Research Scientist at Google DeepMind in New York City. Before that, I was as a Postdoctoral Researcher at Meta working on new approaches for generative modeling and self-supervised learning on audio-visual speech. At Meta, my main project was Automated Dubbing for Instagrams Reels, where I worked on speech-driven facial animation/lip synchronization.

ğŸ“š I completed my BSc in Information Systems and Computer Engineering at Instituto Superior TÃ©cnico, as well as my MSc and PhD in Computing at Imperial College London.

ğŸ–¥ï¸ I spent a substantial portion of my PhD interning and working at Meta AI, where I collaborated with multiple teams and developed my PhD research. I also joined Sony R&D in Tokyo briefly after completing my PhD, as a research intern, where I worked on video-to-audio generation.

ğŸ”¬ğŸ¤– My research is focused on deep learning applied to audio-visual speech (i.e., faces, lip movements, and speech). In particular, I am interested in applying self-supervised learning to learn from unlabelled audio-visual speech. I am also interested and have experience in generative modeling, particularly in generating speech using generative adversarial networks (GANs) and diffusion models.

- ğŸ“« How to reach me: mirarodrigo607(at)ic.ac.uk.
- Personal page: https://miraodasilva.github.io/
- Google Scholar: https://scholar.google.com/citations?user=08YfKjcAAAAJ&hl
- ResearchGate: https://www.researchgate.net/profile/Rodrigo_Mira3
- Twitter: https://twitter.com/RodrigomiraA
- Reddit: https://www.reddit.com/user/MiraoDaSilva
- Linkedin: https://www.linkedin.com/in/https://www.linkedin.com/in/rodrigo-mira-670bbb151/
- YouTube: https://www.youtube.com/@rodrigomiraai2111
- ORCID: https://orcid.org/my-orcid?orcid=0000-0002-9493-3842
<!---
miraodasilva/miraodasilva is a âœ¨ special âœ¨ repository because its `README.md` (this file) appears on your GitHub profile.
You can click the Preview link to take a look at your changes.
--->
